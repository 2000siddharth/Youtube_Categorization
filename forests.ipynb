{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "forests.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOOJ/i/Ydpbzm6HECRfBeF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2000siddharth/web_scraping_classification/blob/master/forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqmCi53r2q-z",
        "colab_type": "code",
        "outputId": "265a36a4-b447-4bf9-de82-eaa5bce57dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import sqlite3\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import classification_report\n",
        "from prettytable import PrettyTable\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsK6u2Z735Yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('combined_youtube4.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFiPt7Uw4I2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleaner(phrase):\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can't\", 'can not', phrase)\n",
        "  \n",
        "  # general\n",
        "    phrase = re.sub(r\"n\\'t\",\" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re'\",\" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\",\" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\",\" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\",\" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\",\" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\",\" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\",\" am\", phrase)\n",
        "    \n",
        "    return phrase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iodtm0Ds4Lkh",
        "colab_type": "code",
        "outputId": "a1ad2974-dff9-4956-8f7f-f96395edc7a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop = set(stopwords.words('english'))\n",
        "len(stop)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9qqAFAs4Oao",
        "colab_type": "code",
        "outputId": "98a851c4-5db8-48d8-d6e1-ae2a39898588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "cleaned_description = []\n",
        "\n",
        "for sentance in tqdm(df['description'].values):\n",
        "    sentance = str(sentance)\n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "    sentance = cleaner(sentance)\n",
        "    sentance = re.sub(r'[?|!|\\'|\"|#|+]', r'', sentance)\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stop)\n",
        "    cleaned_description.append(sentance.strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 31%|███       | 3187/10275 [00:00<00:01, 3817.29it/s]/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
            "  ' Beautiful Soup.' % markup)\n",
            "100%|██████████| 10275/10275 [00:02<00:00, 3881.60it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sPjUtPI4RfG",
        "colab_type": "code",
        "outputId": "5a37a5a8-d09e-4f79-e376-13343fb96392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cleaned_title = []\n",
        "\n",
        "for sentance in tqdm(df['title'].values):\n",
        "    sentance = str(sentance)\n",
        "    sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "    sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "    sentance = cleaner(sentance)\n",
        "    sentance = re.sub(r'[?|!|\\'|\"|#|+]', r'', sentance)\n",
        "    sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "    sentance = re.sub('[^A-Za-z]+', ' ', sentance)\n",
        "    sentance = ' '.join(e.lower() for e in sentance.split() if e.lower() not in stop)\n",
        "    cleaned_title.append(sentance.strip())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10275/10275 [00:02<00:00, 4244.15it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pvvowdu4Ufv",
        "colab_type": "code",
        "outputId": "b01e5c96-24ff-4c58-a7c8-9ce6b43aa0c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df['title'] = cleaned_title\n",
        "\n",
        "df['description'] = cleaned_description\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.youtube.com/watch?v=J8XJjkA5NuQ</td>\n",
              "      <td>dr p j abdul kalam lecture series iit bombay</td>\n",
              "      <td>techfest iit bombay presents dr p j abdul kala...</td>\n",
              "      <td>tutorial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.youtube.com/watch?v=C31hcftHBIk</td>\n",
              "      <td>lecture laa ke nachhatar gill full video song ...</td>\n",
              "      <td>angel records presents new punjabi song lectur...</td>\n",
              "      <td>tutorial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.youtube.com/watch?v=Xn7KWR9EOGQ</td>\n",
              "      <td>basics stock market beginners lecture ca racha...</td>\n",
              "      <td>get lectures new website opportunity learn con...</td>\n",
              "      <td>tutorial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.youtube.com/watch?v=FPaByTt1Yws</td>\n",
              "      <td>musique classique pour la lecture de mozart ch...</td>\n",
              "      <td>musique classique pour la lecture de mozart ch...</td>\n",
              "      <td>tutorial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.youtube.com/watch?v=ViyG77Bca4I</td>\n",
              "      <td>pte retell lecture january february predicted ...</td>\n",
              "      <td>practice session covers pte retell lecture rea...</td>\n",
              "      <td>tutorial</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      video_id  ...  category\n",
              "0  https://www.youtube.com/watch?v=J8XJjkA5NuQ  ...  tutorial\n",
              "1  https://www.youtube.com/watch?v=C31hcftHBIk  ...  tutorial\n",
              "2  https://www.youtube.com/watch?v=Xn7KWR9EOGQ  ...  tutorial\n",
              "3  https://www.youtube.com/watch?v=FPaByTt1Yws  ...  tutorial\n",
              "4  https://www.youtube.com/watch?v=ViyG77Bca4I  ...  tutorial\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPcKfPvV4YYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "\n",
        "labels = LabelEncoder()\n",
        "df['categoryid'] = labels.fit_transform(df['category'])\n",
        "\n",
        "X = df['title']\n",
        "y = df['categoryid']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL6nLFZ34cRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "sss.get_n_splits(X, y)\n",
        "\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "#    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    X_Train, X_test = X[train_index], X[test_index]\n",
        "    y_Train, y_test = y[train_index], y[test_index] \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_cross, y_train, y_cross = train_test_split(X_Train, y_Train, random_state=0, stratify=y_Train, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb2NsVxA4frz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "count_vect.fit(X_train)\n",
        "X_train_counts = count_vect.transform(X_train)\n",
        "X_cross_counts = count_vect.transform(X_cross)\n",
        "X_test_counts = count_vect.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qecgfOQ4jY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXWLs1Qz4o0d",
        "colab_type": "code",
        "outputId": "68771731-3af4-4125-aae2-7ae37f84a273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "rf_0 = RandomForestClassifier(random_state = 8)\n",
        "\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(rf_0.get_params())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'class_weight': None,\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 8,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNhmZWpV42o2",
        "colab_type": "code",
        "outputId": "646a4448-b671-4d69-8727-59bf143419ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# n_estimators\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)]\n",
        "\n",
        "# max_features\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# max_depth\n",
        "max_depth = [int(x) for x in np.linspace(20, 100, num = 5)]\n",
        "max_depth.append(None)\n",
        "\n",
        "# min_samples_split\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "# min_samples_leaf\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# bootstrap\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "pprint(random_grid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [20, 40, 60, 80, 100, None],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [200, 400, 600, 800, 1000]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9UNNAB8B9ax",
        "colab_type": "code",
        "outputId": "6f9452ed-db08-4ad5-cc04-98676d1dbef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "# First create the base model to tune\n",
        "rfc = RandomForestClassifier(random_state=8)\n",
        "\n",
        "# Definition of the random search\n",
        "random_search = RandomizedSearchCV(estimator=rfc,\n",
        "                                   param_distributions=random_grid,\n",
        "                                   n_iter=50,\n",
        "                                   scoring='accuracy',\n",
        "                                   cv=3, \n",
        "                                   verbose=1, \n",
        "                                   random_state=8)\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_train_counts, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 48.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs...\n",
              "                   iid='deprecated', n_iter=50, n_jobs=None,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [20, 40, 60, 80, 100,\n",
              "                                                      None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': [1, 2, 4],\n",
              "                                        'min_samples_split': [2, 5, 10],\n",
              "                                        'n_estimators': [200, 400, 600, 800,\n",
              "                                                         1000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=8, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NRwDSo4CkQ7",
        "colab_type": "code",
        "outputId": "04e4aa78-ac09-4510-b967-25f491686903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print(\"The best hyperparameters from Random Search are:\")\n",
        "print(random_search.best_params_)\n",
        "print(\"\")\n",
        "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
        "print(random_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best hyperparameters from Random Search are:\n",
            "{'n_estimators': 800, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
            "\n",
            "The mean accuracy of a model with these hyperparameters is:\n",
            "0.8909164639091647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEd9NTcKGR1j",
        "colab_type": "code",
        "outputId": "627480d6-4c58-4ba1-b05b-2dd818e450e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "# Create the parameter grid based on the results of random search \n",
        "bootstrap = [False]\n",
        "max_depth = [30, 40, 50]\n",
        "max_features = ['sqrt']\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "min_samples_split = [5, 10, 15]\n",
        "n_estimators = [800]\n",
        "\n",
        "param_grid = {\n",
        "    'bootstrap': bootstrap,\n",
        "    'max_depth': max_depth,\n",
        "    'max_features': max_features,\n",
        "    'min_samples_leaf': min_samples_leaf,\n",
        "    'min_samples_split': min_samples_split,\n",
        "    'n_estimators': n_estimators\n",
        "}\n",
        "\n",
        "# Create a base model\n",
        "rfc = RandomForestClassifier(random_state=8)\n",
        "\n",
        "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
        "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
        "\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator=rfc, \n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=cv_sets,\n",
        "                           verbose=1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train_counts, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed: 24.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=8, test_size=0.33, train_size=None),\n",
              "             error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_sampl...\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=8,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'bootstrap': [False], 'max_depth': [30, 40, 50],\n",
              "                         'max_features': ['sqrt'],\n",
              "                         'min_samples_leaf': [1, 2, 4],\n",
              "                         'min_samples_split': [5, 10, 15],\n",
              "                         'n_estimators': [800]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JydqpnrZGRx2",
        "colab_type": "code",
        "outputId": "270ca711-dc06-49f6-c422-79f828876cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "\n",
        "print(\"The best hyperparameters from Grid Search are:\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"\")\n",
        "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
        "print(grid_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best hyperparameters from Grid Search are:\n",
            "{'bootstrap': False, 'max_depth': 50, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 15, 'n_estimators': 800}\n",
            "\n",
            "The mean accuracy of a model with these hyperparameters is:\n",
            "0.8794703794703795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSYfqro_GQnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_rfc = random_search.best_estimator_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQYL67WtGQkC",
        "colab_type": "code",
        "outputId": "581118f3-061b-4e2d-8cdc-5a3297d52fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "best_rfc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=10,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=800,\n",
              "                       n_jobs=None, oob_score=False, random_state=8, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj_GEi7iGQgc",
        "colab_type": "code",
        "outputId": "345465cd-0217-4993-8e9a-242da9963bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "best_rfc.fit(X_train_counts, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=10,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=800,\n",
              "                       n_jobs=None, oob_score=False, random_state=8, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4KyOEotGQcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc_pred = best_rfc.predict(X_test_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDxKaY9fcs1j",
        "colab_type": "code",
        "outputId": "f5c5f406-df21-43ff-8e46-fdab34ad169c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Training accuracy\n",
        "print(\"The training accuracy is: \")\n",
        "print(accuracy_score(y_train, best_rfc.predict(X_train_counts)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy is: \n",
            "0.9716139497161395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n-pSajYfIB0",
        "colab_type": "code",
        "outputId": "b159421e-11d1-4a4e-9d4f-fd14f2294740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Test accuracy\n",
        "print(\"The test accuracy is: \")\n",
        "print(accuracy_score(y_test, rfc_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test accuracy is: \n",
            "0.8734793187347932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBRfqZwvfOth",
        "colab_type": "code",
        "outputId": "5dbaedb2-d012-44fd-b357-8d10d65730bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# Classification report\n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test, rfc_pred, target_names=df['category'].unique()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    tutorial       0.96      0.85      0.90       210\n",
            "     science       0.61      0.66      0.63       206\n",
            "        vlog       0.96      0.96      0.96       208\n",
            "        food       0.93      0.97      0.95       188\n",
            "     fashion       0.95      0.99      0.97       208\n",
            "      travel       0.97      0.95      0.96       218\n",
            "       music       0.96      0.97      0.96       192\n",
            "      movies       0.95      0.97      0.96       204\n",
            "     history       0.66      0.55      0.60       222\n",
            "         art       0.80      0.92      0.86       199\n",
            "\n",
            "    accuracy                           0.87      2055\n",
            "   macro avg       0.87      0.88      0.87      2055\n",
            "weighted avg       0.87      0.87      0.87      2055\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zmz9NeKfmzC",
        "colab_type": "code",
        "outputId": "e94ddb2a-38c0-4ee4-9b2d-79c947c2a38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "print(\"Confusion Matrix\")\n",
        "print(confusion_matrix(y_test, rfc_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[179   1   3   2   1   1   1   1   2  19]\n",
            " [  1 135   0   3   0   2   3   0  57   5]\n",
            " [  0   0 199   0   1   0   0   3   0   5]\n",
            " [  0   1   1 182   1   0   0   2   1   0]\n",
            " [  0   0   0   1 205   0   0   0   0   2]\n",
            " [  0   0   1   1   2 207   0   1   1   5]\n",
            " [  3   0   0   1   1   0 186   0   0   1]\n",
            " [  0   0   1   0   0   0   0 197   0   6]\n",
            " [  3  84   0   4   0   3   3   0 122   3]\n",
            " [  1   1   2   1   5   0   1   4   1 183]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlAGthsnfyII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi_UZaUdgAnX",
        "colab_type": "code",
        "outputId": "2c8898f7-fac6-47dc-9415-b9706e1bc565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "base_model = RandomForestClassifier(random_state = 8)\n",
        "base_model.fit(X_train_counts, y_train)\n",
        "accuracy_score(y_test, base_model.predict(X_test_counts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8690997566909976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "457PEPnYgAlS",
        "colab_type": "code",
        "outputId": "637e900e-4cd9-470f-bb89-8e77acf4d700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_rfc.fit(X_train_counts, y_train)\n",
        "accuracy_score(y_test, base_model.predict(X_test_counts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8690997566909976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6cXefcrgAiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {\n",
        "     'Model': 'Random Forest',\n",
        "     'Training Set Accuracy': accuracy_score(y_train, best_rfc.predict(X_train_counts)),\n",
        "     'Test Set Accuracy': accuracy_score(y_test, rfc_pred)\n",
        "}\n",
        "\n",
        "df_models_rfc = pd.DataFrame(d, index=[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SpDb57jgAfb",
        "colab_type": "code",
        "outputId": "6deed054-3425-4e10-9ef0-4281c57bd18b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "df_models_rfc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Set Accuracy</th>\n",
              "      <th>Test Set Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.971614</td>\n",
              "      <td>0.873479</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Model  Training Set Accuracy  Test Set Accuracy\n",
              "0  Random Forest               0.971614           0.873479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap151T8KgAcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3n2I9_jpb6Z",
        "colab_type": "text"
      },
      "source": [
        "**Gradient Boosting Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InFQvtAGgAZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buyz3B8wlf3E",
        "colab_type": "code",
        "outputId": "584c85c3-53a9-41a9-bc05-9c795c7b45dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "gb_0 = GradientBoostingClassifier(random_state = 8)\n",
        "\n",
        "print('Parameters currently in use:\\n')\n",
        "pprint(gb_0.get_params())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use:\n",
            "\n",
            "{'ccp_alpha': 0.0,\n",
            " 'criterion': 'friedman_mse',\n",
            " 'init': None,\n",
            " 'learning_rate': 0.1,\n",
            " 'loss': 'deviance',\n",
            " 'max_depth': 3,\n",
            " 'max_features': None,\n",
            " 'max_leaf_nodes': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_iter_no_change': None,\n",
            " 'presort': 'deprecated',\n",
            " 'random_state': 8,\n",
            " 'subsample': 1.0,\n",
            " 'tol': 0.0001,\n",
            " 'validation_fraction': 0.1,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDlbi5pLlfzy",
        "colab_type": "code",
        "outputId": "83a70e2a-3821-4193-f75f-7ad1488cfbab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "n_estimators = [200, 800]\n",
        "\n",
        "# max_features\n",
        "max_features = ['auto', 'sqrt']\n",
        "\n",
        "# max_depth\n",
        "max_depth = [10, 40]\n",
        "max_depth.append(None)\n",
        "\n",
        "# min_samples_split\n",
        "min_samples_split = [10, 30, 50]\n",
        "\n",
        "# min_samples_leaf\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "\n",
        "# learning rate\n",
        "learning_rate = [.1, .5]\n",
        "\n",
        "# subsample\n",
        "subsample = [.5, 1.]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'learning_rate': learning_rate,\n",
        "               'subsample': subsample}\n",
        "\n",
        "pprint(random_grid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'learning_rate': [0.1, 0.5],\n",
            " 'max_depth': [10, 40, None],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [10, 30, 50],\n",
            " 'n_estimators': [200, 800],\n",
            " 'subsample': [0.5, 1.0]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfoS_1K7lfvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbc = GradientBoostingClassifier(random_state=8)\n",
        "\n",
        "# Definition of the random search\n",
        "random_search = RandomizedSearchCV(estimator=gbc,\n",
        "                                   param_distributions=random_grid,\n",
        "                                   n_iter=50,\n",
        "                                   scoring='accuracy',\n",
        "                                   cv=3, \n",
        "                                   verbose=1, \n",
        "                                   random_state=8)\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_train_counts, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd5OovwhlfsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"The best hyperparameters from Random Search are:\")\n",
        "print(random_search.best_params_)\n",
        "print(\"\")\n",
        "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
        "print(random_search.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC9fzd0ZlfoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "# Create the parameter grid based on the results of random search \n",
        "max_depth = [5, 10, 15]\n",
        "max_features = ['sqrt']\n",
        "min_samples_leaf = [2]\n",
        "min_samples_split = [50, 100]\n",
        "n_estimators = [800]\n",
        "learning_rate = [.1, .5]\n",
        "subsample = [1.]\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': max_depth,\n",
        "    'max_features': max_features,\n",
        "    'min_samples_leaf': min_samples_leaf,\n",
        "    'min_samples_split': min_samples_split,\n",
        "    'n_estimators': n_estimators,\n",
        "    'learning_rate': learning_rate,\n",
        "    'subsample': subsample\n",
        "\n",
        "}\n",
        "\n",
        "# Create a base model\n",
        "gbc = GradientBoostingClassifier(random_state=8)\n",
        "\n",
        "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
        "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
        "\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator=gbc, \n",
        "                           param_grid=param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=cv_sets,\n",
        "                           verbose=1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train_counts, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDiArWRWlflR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbc = GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
        "              learning_rate=0.1, loss='deviance', max_depth=15,\n",
        "              max_features='sqrt', max_leaf_nodes=None,\n",
        "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "              min_samples_leaf=2, min_samples_split=50,\n",
        "              min_weight_fraction_leaf=0.0, n_estimators=800,\n",
        "              presort='auto', random_state=8, subsample=1.0, verbose=0,\n",
        "              warm_start=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sndRiPuZlfhU",
        "colab_type": "code",
        "outputId": "c9b5e814-4498-41a2-eddd-5803daa1d404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "gbc.fit(X_train_counts, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py:1342: FutureWarning: The parameter 'presort' is deprecated and has no effect. It will be removed in v0.24. You can suppress this warning by not passing any value to the 'presort' parameter. We also recommend using HistGradientBoosting models instead.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
              "                           learning_rate=0.1, loss='deviance', max_depth=15,\n",
              "                           max_features='sqrt', max_leaf_nodes=None,\n",
              "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                           min_samples_leaf=2, min_samples_split=50,\n",
              "                           min_weight_fraction_leaf=0.0, n_estimators=800,\n",
              "                           n_iter_no_change=None, presort='auto',\n",
              "                           random_state=8, subsample=1.0, tol=0.0001,\n",
              "                           validation_fraction=0.1, verbose=0,\n",
              "                           warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeJd3VCmlffL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbc_pred = gbc.predict(X_test_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqzODrbllfbn",
        "colab_type": "code",
        "outputId": "ff69b6b4-5a8c-4df4-d582-817665af151c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Training accuracy\n",
        "print(\"The training accuracy is: \")\n",
        "print(accuracy_score(y_train, gbc.predict(X_train_counts)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy is: \n",
            "0.9694512030278454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0FVo6ollfXV",
        "colab_type": "code",
        "outputId": "3218cac9-cbb4-46c4-d6ec-3d19b10e84c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Test accuracy\n",
        "print(\"The test accuracy is: \")\n",
        "print(accuracy_score(y_test, gbc_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The test accuracy is: \n",
            "0.8768856447688564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhPOr2NmpKWy",
        "colab_type": "code",
        "outputId": "df9f1957-2c02-4e9b-d89e-3268000e778a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# Classification report\n",
        "print(\"Classification report\")\n",
        "print(classification_report(y_test, gbc_pred, target_names=df['category'].unique()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    tutorial       0.89      0.90      0.90       210\n",
            "     science       0.60      0.63      0.62       206\n",
            "        vlog       0.97      0.94      0.95       208\n",
            "        food       0.94      0.97      0.96       188\n",
            "     fashion       0.94      0.99      0.96       208\n",
            "      travel       0.96      0.94      0.95       218\n",
            "       music       0.97      0.96      0.97       192\n",
            "      movies       0.96      0.97      0.97       204\n",
            "     history       0.62      0.58      0.60       222\n",
            "         art       0.93      0.92      0.93       199\n",
            "\n",
            "    accuracy                           0.88      2055\n",
            "   macro avg       0.88      0.88      0.88      2055\n",
            "weighted avg       0.88      0.88      0.88      2055\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv-KD2NVpUqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUfUh14YK-bE",
        "colab_type": "text"
      },
      "source": [
        "**Ensemble - Stacking Procedure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwffm1j2LE_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JgUbIGyMx83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}